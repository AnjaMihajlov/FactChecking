import asyncio
import datetime

import aiohttp
import json
import csv

# =======================
# Configuration Constants
# =======================
OPENROUTER_API_KEY = "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"

# Endpoints
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"

# Default LLM model (can be changed if desired)
# DEFAULT_MODEL = "anthropic/claude-3.5-haiku"
DEFAULT_MODEL = "gpt-3.5-turbo"


# ============================
# Asynchronous Helper Functions
# ============================
async def call_openrouter_async(session, messages, model=DEFAULT_MODEL):
    """
    Asynchronously call the OpenRouter chat completion API with the provided messages.
    Returns the content of the assistant’s reply.
    """
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "X-Title": "OpenDeepResearcher, by Matt Shumer",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages
    }
    try:
        async with session.post(OPENROUTER_URL, headers=headers, json=payload) as resp:
            if resp.status == 200:
                result = await resp.json()
                try:
                    return result['choices'][0]['message']['content']
                except (KeyError, IndexError) as e:
                    print("Unexpected OpenRouter response structure:", result)
                    return None
            else:
                text = await resp.text()
                print(f"OpenRouter API error: {resp.status} - {text}")
                return None
    except Exception as e:
        print("Error calling OpenRouter:", e)
        return None

async def extract_questions(session, text):
    """
        Function that uses AI model to extract mentioned facts from text and make questions from them.

        Parameters:
        - session (aiohttp.ClientSession): The session used for making HTTP requests.
        - text (str): Text from which we make exreactions.

        Returns:
        - report (str): A list of questions generated by AI.
    """
    prompt = (
        "You are an expert information extractor. From the text that is sent to you, extract all facts that are said and that can be checked for truthfullness by searching through the internet, turn them into a question that has a format of 'Yes' or 'No' answer and make a list of all these questions."
    )
    messages = [
        {"role": "system", "content": "You are a skilled information extractor."},
        {"role": "user",
         "content": f"Text: {text}\n\n{prompt}"}
    ]
    report = await call_openrouter_async(session, messages)
    return report

QUERY_INDEX = 0
ANSWER_INDEX = 1
EXPECTED_INDEX = 2
PRECISION_INDEX = 3
LINKS_INDEX = 4

PATH_SPEECH =".\\speeches\\"
SPEECH_FILE_NAME= "govor_vucic_izbori_2017.txt"     # Change SPEECH_FILE_NAME when reading new text
PATH_TO_TEXT = PATH_SPEECH + SPEECH_FILE_NAME

PATH_DATA = ".\\data\\"     
CSV_FILE_NAME = "data_jagodina.csv"                 # Change CSV_FILE_NAME when writing a new one
PATH_TO_CSV_FILE = PATH_DATA + CSV_FILE_NAME

PATH_PRECISION = ".\\precision\\"
LOG_FILE_NAME = "precision_log.txt"                  # Don't change
PATH_TO_LOG_FILE = PATH_PRECISION + LOG_FILE_NAME

PATH_QUESTIONS = ".\\questions\\"
QUESTIONS_FILE_NAME = "izdvojena_pitanja_jagodina.txt"              # Change QUESTIONS_FILE_NAME when reading from a new example
PATH_TO_QUESTIONS_FILE = PATH_QUESTIONS + QUESTIONS_FILE_NAME

HEADER = "Pitanje, Odgovor, Očekivan odgovor, Tačnost, Linkovi, Likovi za referencu\n"

def read_file(filename):
    """
        Reads a TXT file and extracts its contents

        Parameters:
        - filename (str): The path to the file.

        Returns:
        - Extracted text (str)
    """
    with open(filename, "r", encoding="utf-8") as file:
        text = file.read()
        return text


# Funkcija za upisivanje odgovora u CSV fajl
def write_results(csv_filename, data):
    """
        Writes generated questions to a CSV file:
        - Updates the question column (0).
        - Stores the links used for each query.
        - Calculates and records the overall accuracy percentage in log file.

        Parameters:
        - filename (str): The path to the output CSV file.
        - data (List[str]): A list of generated answers.
        - rows (List[List[str]]): The original CSV data without header.
        - links_used (List[str]): A list of links used for each query.
    """
    rows = []
    for i, value in enumerate(data):
        rows.append(value+",,,,,,\n")

    # Write back to the CSV file
    with open(csv_filename, "w", encoding="utf-8", newline="") as file:
        file.write(HEADER)              # Write the header row
        file.write("".join(rows))
    
async def asyncio_main(text):
    async with aiohttp.ClientSession() as session:
        tasks = [extract_questions(session,text)]    
        result = await asyncio.gather(*tasks)    
        print(result)

def main():
    text = read_file(PATH_TO_QUESTIONS_FILE)
    pitanja_lista = text.split("\n")
    write_results(PATH_TO_CSV_FILE,pitanja_lista)
    # asyncio.run(asyncio_main(text))



if __name__ == "__main__":
    main()